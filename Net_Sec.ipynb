{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m_bvyaqk8kYB"
      },
      "outputs": [],
      "source": [
        "# Efficient Iris Classification with sklearn\n",
        "\n",
        "import pandas as pd  # For loading and handling CSV data\n",
        "from sklearn.model_selection import train_test_split  # For splitting dataset into training and testing sets\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler  # For encoding labels and normalizing features\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix  # Performance metrics\n",
        "from sklearn.svm import SVC  # Support Vector Machine classifier\n",
        "from sklearn.linear_model import LogisticRegression  # Logistic Regression classifier\n",
        "from sklearn.tree import DecisionTreeClassifier  # Decision Tree classifier\n",
        "from sklearn.ensemble import RandomForestClassifier  # Random Forest classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier  # K-Nearest Neighbors classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from CSV file\n",
        "data = pd.read_csv('data_t.csv')  # Reads the CSV into a pandas DataFrame"
      ],
      "metadata": {
        "id": "0rZrjqDsnJWQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Use 'category' column as the label\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data[\"category\"])  # 'Normal' / 'DDoS' â†’ 0 / 1\n",
        "\n",
        "print(label_encoder.classes_)\n",
        "print(pd.crosstab(data[\"category\"], y))\n",
        "\n",
        "# 2) Drop attack/category/subcategory from the features\n",
        "cols_to_drop = [\"attack\", \"category\", \"subcategory\"]\n",
        "features_df = data.drop(columns=cols_to_drop)\n",
        "\n",
        "categorical_cols = [\"proto\", \"flgs\", \"state\", \"saddr\",\"daddr\"]\n",
        "\n",
        "features_encoded = pd.get_dummies(\n",
        "    features_df,\n",
        "    columns=categorical_cols,\n",
        "    drop_first=True\n",
        ")\n",
        "\n",
        "na_counts = features_encoded.isna().sum().sort_values(ascending=False)\n",
        "cols_all_nan = na_counts[na_counts == len(features_encoded)].index\n",
        "features_encoded = features_encoded.drop(columns=cols_all_nan)\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy=\"median\")  # or \"mean\"\n",
        "X = imputer.fit_transform(features_encoded)  # replaces NaNs with column median"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdXt6SbAnL0j",
        "outputId": "5efa2f3b-f7bd-49b2-c88d-1ccaa661fc1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DDoS' 'Normal']\n",
            "col_0        0   1\n",
            "category          \n",
            "DDoS      1044   0\n",
            "Normal       0  65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize features to zero mean and unit variance\n",
        "X = StandardScaler().fit_transform(X)  # StandardScaler scales each feature for better model performance"
      ],
      "metadata": {
        "id": "h1nFJ0eUnQTI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training (70%) and testing (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")  # random_state ensures reproducibility"
      ],
      "metadata": {
        "id": "OToD4NqcnU4m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define multiple classifiers in a dictionary for easy iteration\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=200),  # Logistic Regression, increased max_iter\n",
        "    'Decision Tree': DecisionTreeClassifier(),  # Decision Tree\n",
        "    'Random Forest': RandomForestClassifier(),  # Random Forest\n",
        "    }"
      ],
      "metadata": {
        "id": "RjJ_MsHznXXm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print evaluation metrics\n",
        "def print_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Prints performance metrics for predictions:\n",
        "    - Accuracy\n",
        "    - F1-score\n",
        "    - Recall\n",
        "    - Precision\n",
        "    - Confusion Matrix\n",
        "    - Crosstab for detailed view\n",
        "    \"\"\"\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.2f}\")  # Overall accuracy\n",
        "    print(f\"F1-score: {f1_score(y_true, y_pred, average='weighted'):.3f}\")  # F1-score (weighted)\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, average='weighted'):.3f}\")  # Recall (weighted)\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred, average='weighted'):.3f}\")  # Precision (weighted)\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))  # Confusion matrix\n",
        "    print(pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))  # Crosstab\n",
        "    print('-'*50)  # Separator for readability"
      ],
      "metadata": {
        "id": "sophYk-cnbFX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)  # Train the model on the training set\n",
        "    y_pred = model.predict(X_test)  # Make predictions on the test set\n",
        "    print(f\"{name} Results:\")  # Print model name\n",
        "    print_metrics(y_test, y_pred)  # Print all metrics for this model"
      ],
      "metadata": {
        "id": "mFia6208ndmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc01bd4-a665-4be4-adb8-54fc338b5900"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Results:\n",
            "Accuracy: 1.00\n",
            "F1-score: 1.000\n",
            "Recall: 1.000\n",
            "Precision: 1.000\n",
            "Confusion Matrix:\n",
            " [[313   0]\n",
            " [  0  20]]\n",
            "Predicted    0   1  All\n",
            "True                   \n",
            "0          313   0  313\n",
            "1            0  20   20\n",
            "All        313  20  333\n",
            "--------------------------------------------------\n",
            "Decision Tree Results:\n",
            "Accuracy: 1.00\n",
            "F1-score: 1.000\n",
            "Recall: 1.000\n",
            "Precision: 1.000\n",
            "Confusion Matrix:\n",
            " [[313   0]\n",
            " [  0  20]]\n",
            "Predicted    0   1  All\n",
            "True                   \n",
            "0          313   0  313\n",
            "1            0  20   20\n",
            "All        313  20  333\n",
            "--------------------------------------------------\n",
            "Random Forest Results:\n",
            "Accuracy: 1.00\n",
            "F1-score: 1.000\n",
            "Recall: 1.000\n",
            "Precision: 1.000\n",
            "Confusion Matrix:\n",
            " [[313   0]\n",
            " [  0  20]]\n",
            "Predicted    0   1  All\n",
            "True                   \n",
            "0          313   0  313\n",
            "1            0  20   20\n",
            "All        313  20  333\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}